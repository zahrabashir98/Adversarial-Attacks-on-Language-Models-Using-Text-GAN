{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualization + other models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "asKdXaF6QTTf"
      },
      "source": [
        "%pip install hickle\n",
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "import hickle as hkl\n",
        "    \n",
        "# def save_vocab(vocab, path):\n",
        "#     with open(path, 'w+') as f:     \n",
        "#         for token, index in vocab.stoi.items():\n",
        "#             f.write(f'{index}\\t{token}')\n",
        "\n",
        "# def read_vocab(path):\n",
        "#     vocab = dict()\n",
        "#     with open(path, 'r') as f:\n",
        "#         for line in f:\n",
        "#             index, token = line.split('\\t')\n",
        "#             vocab[token] = int(index)\n",
        "#     return vocab\n",
        "import pickle\n",
        "\n",
        "def save_vocab(vocab, path):\n",
        "    output = open(path, 'wb')\n",
        "    pickle.dump(vocab, output)\n",
        "    output.close()\n",
        "\n",
        "def read_vocab(path):\n",
        "    output = open(path, 'rb')\n",
        "    vocab = pickle.load(output)\n",
        "    output.close()\n",
        "    return vocab\n",
        "\n",
        "def print_closest_words(vec, n=5):\n",
        "    dists = torch.norm(glove.vectors - vec, dim=1)     # compute distances to all words\n",
        "    lst = sorted(enumerate(dists.numpy()), key=lambda x: x[1]) # sort by distance\n",
        "    for idx, difference in lst[0:n+1]: \t\t\t\t\t       # take the top n\n",
        "        print(glove.itos[idx], difference)\n",
        "\n",
        "\n",
        "# print_closest_words(glove[\"cat\"], n=1)\n",
        "\n",
        "def get_embedding(dataset):\n",
        "    # The first time you run this will download a ~823MB file\n",
        "    glove = torchtext.vocab.GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "                                  dim=50)   # embedding size = 100\n",
        "\n",
        "    save_vocab(glove, \"/content/drive/MyDrive/MLprj/test2000\")\n",
        "    print(\"=>>\", len(glove), glove)\n",
        "    encoded = []\n",
        "    for sentence in dataset:\n",
        "        encoded.append([glove[word] for word in sentence])\n",
        "    \n",
        "    return encoded\n",
        "    \n",
        "def load_data():\n",
        "        array_hkl = hkl.load('data_new2000.hkl')\n",
        "        X_train = array_hkl['xtrain']\n",
        "        X_test = array_hkl['xtest']\n",
        "        y_train = array_hkl['ytrain']\n",
        "        y_test = array_hkl['ytest']\n",
        "\n",
        "        word_index = imdb.get_word_index()\n",
        "        # step 2: reverse word index to map integer indexes to their respective words\n",
        "        reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "        train_sentences = []\n",
        "        for i  in  range(len(X_train)):\n",
        "\n",
        "          decoded_review = [reverse_word_index.get(i - 3, '?') for i in X_train[i]]\n",
        "          if not len(X_train[i])==len(decoded_review):\n",
        "              print(len(decoded_review))\n",
        "          train_sentences.append(decoded_review)\n",
        "        print(np.array(train_sentences).shape)\n",
        "        return train_sentences, y_train \n",
        "\n",
        "a, b = load_data()\n",
        "get_embedding(a)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "glove = read_vocab(\"/content/drive/MyDrive/MLprj/test2000\")\n",
        "print(glove)\n",
        "print(glove[\"cat\"])\n",
        "print(glove[\"cat\"].shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXMFM47Nn99E"
      },
      "source": [
        "train = a \n",
        "# glove = torchtext.vocab.GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "#                               dim=50)   # embedding size = 100\n",
        "# word_index = imdb.get_word_index()\n",
        "words_list = []\n",
        "vectors = []\n",
        "word_index = imdb.get_word_index()\n",
        "        # step 2: reverse word index to map integer indexes to their respective words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "print(reverse_word_index)\n",
        "\n",
        "for i in range(3, 3053): \n",
        "    word = reverse_word_index.get(i-3, '?')\n",
        "    vectors.append(glove[word])\n",
        "    words_list.append(word)\n",
        "\n",
        "\n",
        "def print_closest_words(vec):\n",
        "    closest_dist = 10000000\n",
        "    closest_word = -100\n",
        "    counter = 0 \n",
        "    for v in vectors: \n",
        "        if words_list[counter]==\"cat\" or words_list[counter]==\"dog\": \n",
        "          print(torch.norm(v - vec))\n",
        "          print(words_list[counter])\n",
        "        dist = torch.norm(v - vec)\n",
        "        if closest_dist >= dist: \n",
        "            closest_word = counter \n",
        "            closest_dist = dist\n",
        "\n",
        "        counter += 1\n",
        "    return words_list[closest_word], closest_dist\n",
        "\n",
        "print(print_closest_words(glove[\"cat\"]))\n",
        "print(glove[\"cat\"].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rfw6ru3sUPL"
      },
      "source": [
        "word_to_vec = hkl.load('word_to_vec.hkl')\n",
        "words_list = word_to_vec[\"words_list\"]\n",
        "vectors = word_to_vec[\"vectors\"] \n",
        "\n",
        "def print_closest_words(vec):\n",
        "    dists = torch.norm(vectors - vec, dim=1)     # compute distances to all words\n",
        "    lst = sorted(enumerate(dists.numpy()), key=lambda x: x[1]) # sort by distance\n",
        "    for idx, difference in lst[0]: \t\t\t\t\t       # take the top n\n",
        "        print(glove.itos[idx], difference)\n",
        "        return glove.itos[idx]\n",
        "\n",
        "print(print_closest_words(glove[\"cat\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-A83NE6l_JI"
      },
      "source": [
        "glove = torchtext.vocab.GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "                              dim=50) \n",
        "len(glove[\"?\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7_NRpvQOfy5",
        "outputId": "9bd5d6f0-a41e-49aa-eca9-435bda7eb787"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the data, keeping only 10,000 of the most frequently occuring words\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 1000)\n",
        "\n",
        "print()\n",
        "\n",
        "# step 1: load the dictionary mappings from word to integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# step 2: reverse word index to map integer indexes to their respective words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Step 3: decode the review, mapping integer indices to words\n",
        "#\n",
        "# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\"\n",
        "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[10]])\n",
        "\n",
        "decoded_review\n",
        "\n",
        "\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=1000):\n",
        "    results = np.zeros((len(sequences), dimension))    # Creates an all zero matrix of shape (len(sequences),10K)\n",
        "    for i,sequence in enumerate(sequences):\n",
        "        results[i,sequence] = 1                        # Sets specific indices of results[i] to 1s\n",
        "    return results\n",
        "\n",
        "# Vectorize training Data\n",
        "print(train_data[0])\n",
        "X_train = vectorize_sequences(train_data)\n",
        "print(X_train[0])\n",
        "# Vectorize testing Data\n",
        "X_test = vectorize_sequences(test_data)\n",
        "\n",
        "MAX_LENGTH= 300\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_LENGTH)\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
            "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyFg_RCRFGTn",
        "outputId": "eb0a4e4b-7b6d-4dd5-cb2e-03c5b25ebe57"
      },
      "source": [
        "%pip install tensorflow==2.4\n",
        "%pip install keras==2.4.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/0a/012cc33c643d844433d13001dd1db179e7020b05ddbbd0a9dc86c38a8efa/tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (2.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (0.36.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (2.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (3.12.4)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (0.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (1.27.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (54.1.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4) (3.7.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4) (3.4.1)\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed tensorflow-2.4.0\n",
            "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.3) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNpuJUAZqhfz"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8MGSEqW0yEY",
        "outputId": "a2a3e44f-291d-4fd4-c5bd-fe55f7d4bca5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u45qJp5TqmgG",
        "outputId": "61fb5259-ed4b-48a5-a59b-603138999230"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = X_train, X_test, train_labels, test_labels  \n",
        "print(X_train)\n",
        "bnb = BernoulliNB(binarize=0.0)\n",
        "bnb.fit(X_train, Y_train)\n",
        "print(bnb.score(X_test, Y_test))\n",
        "y_pred = bnb.predict(X_train)\n",
        "train_acc = accuracy_score(Y_train, y_pred)\n",
        "print(\"accuracy:\", train_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "0.7076\n",
            "accuracy: 0.7162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klGISUyz1Kbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a5a77d-8996-42a6-a7e3-6a94cbc4ca10"
      },
      "source": [
        "bnb.predict(X_train)[10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsQHGatwYib6"
      },
      "source": [
        "from keras import objectives, backend as K\n",
        "from keras.layers import Bidirectional, Dense, Embedding, Input, Lambda, LSTM, RepeatVector, TimeDistributed\n",
        "from keras.models import Model\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "class VAE(object):\n",
        "    def create(self, vocab_size=1000, max_length=300, latent_rep_size=1000):\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.sentiment_predictor = None\n",
        "        self.autoencoder = None\n",
        "\n",
        "        x = Input(shape=(max_length,))\n",
        "        x_embed = Embedding(vocab_size, 128, input_length=max_length)(x)\n",
        "\n",
        "        vae_loss, encoded = self._build_encoder(x_embed, latent_rep_size=latent_rep_size, max_length=max_length)\n",
        "        self.encoder = Model(inputs=x, outputs=encoded)\n",
        "\n",
        "        encoded_input = Input(shape=(latent_rep_size,))\n",
        "        predicted_sentiment = self._build_sentiment_predictor(encoded_input)\n",
        "        self.sentiment_predictor = Model(encoded_input, predicted_sentiment)\n",
        "\n",
        "        decoded = self._build_decoder(encoded_input, vocab_size, max_length)\n",
        "        self.decoder = Model(encoded_input, decoded)\n",
        "\n",
        "        self.autoencoder = Model(inputs=x, outputs=[self._build_decoder(encoded, vocab_size, max_length)])\n",
        "        # self.autoencoder.add_loss(vae_loss)\n",
        "        self.autoencoder.compile(optimizer='Adam', loss = vae_loss,\n",
        "                                 metrics=['accuracy'])\n",
        "        print(\"creation done!\")\n",
        "\n",
        "    def _build_encoder(self, x, latent_rep_size=1000, max_length=300, epsilon_std=0.01):\n",
        "        h = Bidirectional(LSTM(500, return_sequences=True, name='lstm_1'), merge_mode='concat')(x)\n",
        "        h = Bidirectional(LSTM(500, return_sequences=False, name='lstm_2'), merge_mode='concat')(h)\n",
        "        h = Dense(2000, activation='relu', name='dense_1')(h)\n",
        "\n",
        "        def sampling(args):\n",
        "            z_mean_, z_log_var_ = args\n",
        "            batch_size = K.shape(z_mean_)[0]\n",
        "            epsilon = K.random_normal(shape=(batch_size, latent_rep_size), mean=0., stddev=epsilon_std)\n",
        "            return z_mean_ + K.exp(z_log_var_ / 2) * epsilon\n",
        "\n",
        "        z_mean = Dense(latent_rep_size, name='z_mean', activation='linear')(h)\n",
        "        z_log_var = Dense(latent_rep_size, name='z_log_var', activation='linear')(h)\n",
        "\n",
        "        def vae_loss(x, x_decoded_mean):\n",
        "            x = K.flatten(x)\n",
        "            x_decoded_mean = K.flatten(x_decoded_mean)\n",
        "            xent_loss = max_length * objectives.binary_crossentropy(x, x_decoded_mean)\n",
        "            kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "            return xent_loss + kl_loss\n",
        "        print(\"encoder built\")\n",
        "        return (vae_loss, Lambda(sampling, output_shape=(latent_rep_size,), name='lambda')([z_mean, z_log_var]))\n",
        "\n",
        "    def _build_decoder(self, encoded, vocab_size, max_length):\n",
        "        repeated_context = RepeatVector(max_length)(encoded)\n",
        "\n",
        "        h = LSTM(500, return_sequences=True, name='dec_lstm_1')(repeated_context)\n",
        "        h = LSTM(500, return_sequences=True, name='dec_lstm_2')(h)\n",
        "        decoded = TimeDistributed(Dense(vocab_size, activation='softmax'), name='decoded_mean')(h)\n",
        "        print(\"decoder built\")\n",
        "        return decoded\n",
        "\n",
        "    def _build_sentiment_predictor(self, encoded):\n",
        "        h = Dense(100, activation='linear')(encoded)\n",
        "        print(\"sentiment done\")\n",
        "        return Dense(1, activation='sigmoid', name='pred')(h)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL1zKihdJUly"
      },
      "source": [
        "from keras import objectives, backend as K \n",
        "from keras.layers import Bidirectional, Dense, Embedding, Input, Lambda, LSTM, RepeatVector, TimeDistributed \n",
        "from keras.models import Model \n",
        "import keras\n",
        "\n",
        "class AE(object): \n",
        "  def create(self, vocab_size=1000, max_length=200, latent_rep_size=300): \n",
        "    self.encoder = None \n",
        "    self.decoder = None \n",
        "    self.autoencoder = None\n",
        "\n",
        "    x = Input(shape=(max_length,))\n",
        "    x_embed = Embedding(vocab_size, 128, input_length=max_length)(x)\n",
        " \n",
        "    encoded, vae_loss = self._build_encoder(x_embed, latent_rep_size=latent_rep_size, max_length=max_length)\n",
        "    self.encoder = Model(inputs=x, outputs=encoded)\n",
        " \n",
        "    encoded_input = Input(shape=(latent_rep_size,))\n",
        "    # predicted_sentiment = self._build_sentiment_predictor(encoded_input)\n",
        "    # self.sentiment_predictor = Model(encoded_input, predicted_sentiment)\n",
        "    print(\"111111111\")\n",
        "    decoded = self._build_decoder(encoded_input, vocab_size, max_length)\n",
        "    self.decoder = Model(encoded_input, decoded)\n",
        " \n",
        "    self.autoencoder = Model(inputs=x, outputs=[self._build_decoder(encoded, vocab_size, max_length)])\n",
        " \n",
        "    self.autoencoder.compile(optimizer='Adam', loss=vae_loss,\n",
        "                             metrics=['accuracy'])\n",
        "    print(\"creation done!\")\n",
        " \n",
        "  def _build_encoder(self, x, latent_rep_size=1000, max_length=200, epsilon_std=0.01):\n",
        "    h = Bidirectional(LSTM(500, return_sequences=True, name='lstm_1'), merge_mode='concat')(x)\n",
        "    h = Bidirectional(LSTM(500, return_sequences=False, name='lstm_2'), merge_mode='concat')(h)\n",
        "    h = Dense(500, activation='relu', name='dense_1')(h)\n",
        "    encoded = Dense(latent_rep_size, name='dense_2', activation='linear')(h)\n",
        " \n",
        "    def vae_loss(x, x_decoded_mean):\n",
        "        x = K.flatten(x)\n",
        "        x_decoded_mean = K.flatten(x_decoded_mean)\n",
        "        xent_loss = max_length * objectives.binary_crossentropy(x, x_decoded_mean)\n",
        "        return xent_loss \n",
        " \n",
        "    print(\"encoder built\")\n",
        "    return encoded, vae_loss\n",
        " \n",
        "  def _build_decoder(self, encoded, vocab_size, max_length):\n",
        "    repeated_context = RepeatVector(max_length)(encoded)\n",
        "    h = LSTM(500, return_sequences=True, name='dec_lstm_1')(repeated_context)\n",
        "    h = LSTM(500, return_sequences=True, name='dec_lstm_2')(h)\n",
        "    decoded = TimeDistributed(Dense(vocab_size, activation='softmax'), name='decoded_mean')(h)\n",
        "    print(\"decoder built\")\n",
        "    return decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPDA8VSTXpl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1378587-d654-4be5-f05c-7e825c56d457"
      },
      "source": [
        "!pip install hickle\n",
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# from model import VAE\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "disable_eager_execution()\n",
        "\n",
        "# import tensorflow as tf\n",
        "# tf.config.experimental_run_functions_eagerly(True)\n",
        "\n",
        "MAX_LENGTH = 200\n",
        "NUM_WORDS = 1000\n",
        "\n",
        "# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
        "\n",
        "import hickle as hkl\n",
        "\n",
        "# X_train = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
        "# X_test = pad_sequences(X_test, maxlen=MAX_LENGTH)\n",
        "\n",
        "\n",
        "# train_indices = np.random.choice(np.arange(X_train.shape[0]),  3000, replace=False)\n",
        "# test_indices = np.random.choice(np.arange(X_test.shape[0]), 1000, replace=False)\n",
        "\n",
        "# X_train = X_train[train_indices]\n",
        "# y_train = y_train[train_indices]\n",
        "\n",
        "# X_test = X_test[test_indices]\n",
        "# y_test = y_test[test_indices]\n",
        "\n",
        "array_hkl = hkl.load('/content/drive/MyDrive/MLprj/data_3000.hkl')\n",
        "X_train = array_hkl['xtrain']\n",
        "X_test = array_hkl['xtest']\n",
        "y_train = array_hkl['ytrain']\n",
        "y_test = array_hkl['ytest']\n",
        "\n",
        "temp = np.zeros((X_train.shape[0], MAX_LENGTH, NUM_WORDS))\n",
        "temp[np.expand_dims(np.arange(X_train.shape[0]), axis=0).reshape(X_train.shape[0], 1), np.repeat(np.array([np.arange(MAX_LENGTH)]), X_train.shape[0], axis=0), X_train] = 1\n",
        "\n",
        "X_train_one_hot = temp\n",
        "\n",
        "temp = np.zeros((X_test.shape[0], MAX_LENGTH, NUM_WORDS))\n",
        "temp[np.expand_dims(np.arange(X_test.shape[0]), axis=0).reshape(X_test.shape[0], 1), np.repeat(np.array([np.arange(MAX_LENGTH)]), X_test.shape[0], axis=0), X_test] = 1\n",
        "\n",
        "x_test_one_hot = temp\n",
        "\n",
        "\n",
        "\n",
        "def create_model_checkpoint(dir, model_name):\n",
        "    filepath = dir + '/' + \\\n",
        "               model_name + \"-{epoch:02d}.h5\"\n",
        "    print(\"=>\", filepath)  \n",
        "    directory = os.path.dirname(filepath)\n",
        "\n",
        "    try:\n",
        "        os.stat(directory)\n",
        "    except:\n",
        "        os.mkdir(directory)\n",
        "\n",
        "    checkpointer = ModelCheckpoint(filepath=filepath,\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=False)\n",
        "\n",
        "    return checkpointer\n",
        "\n",
        "\n",
        "def train():\n",
        "    model = AE()\n",
        "    model.create(vocab_size=NUM_WORDS, max_length=MAX_LENGTH)\n",
        "\n",
        "    checkpointer = create_model_checkpoint('/content/drive/MyDrive/adverserial', 'rnn_myae_final_')\n",
        "\n",
        "    model.autoencoder.fit(x=X_train, y={'decoded_mean': X_train_one_hot, 'pred': y_train},\n",
        "                            batch_size=10, epochs=3, callbacks=[checkpointer],\n",
        "                            validation_data=(X_test, {'decoded_mean': x_test_one_hot, 'pred':  y_test}))\n",
        "    \n",
        "    # p = model.autoencoder.predict(x_test_one_hot[0])\n",
        "    # print(p)\n",
        "    return model\n",
        "\n",
        "model = train()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hickle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/ee/7f442cb653c22f6f1d9de922919be58d81bc8a09ec4f6d886ce447683596/hickle-4.0.4-py3-none-any.whl (49kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 20kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 40kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (0.3.3)\n",
            "Requirement already satisfied: h5py<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (2.10.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.19.5)\n",
            "Installing collected packages: hickle\n",
            "Successfully installed hickle-4.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ3hSdYMfK1w",
        "outputId": "aa55cbdd-1a14-40d7-9dd5-0857c6ba9c40"
      },
      "source": [
        "# import numpy; print(python.__version__)\n",
        "!python --version\n",
        "!python -c \"import numpy; print(numpy.__version__)\"\n",
        "!python -c \"import tensorflow; print(tensorflow.__version__)\"\n",
        "!python -c \"import keras; print(keras.__version__)\"\n",
        "!pip install hickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n",
            "1.19.5\n",
            "2021-04-05 17:05:03.885553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2.4.1\n",
            "2021-04-05 17:05:06.006428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2.4.3\n",
            "Collecting hickle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/ee/7f442cb653c22f6f1d9de922919be58d81bc8a09ec4f6d886ce447683596/hickle-4.0.4-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (0.3.3)\n",
            "Requirement already satisfied: h5py<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (2.10.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.19.5)\n",
            "Installing collected packages: hickle\n",
            "Successfully installed hickle-4.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGIXC_sVqhXb"
      },
      "source": [
        "# **Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arCObb-YQEEh",
        "outputId": "ec2dc7dd-5516-44f5-824f-822992b8d655"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hickle in /usr/local/lib/python3.7/dist-packages (4.0.4)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.15.0)\n",
            "Requirement already satisfied: h5py<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.19.5)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (0.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1njWGmay8_J2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86cbf606-fbca-414c-f711-bca7cb5bfce4"
      },
      "source": [
        "print(reconstructed_model.layers[5].input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"dense_1/Relu:0\", shape=(None, 500), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwGYKEG70tJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bb1f23-4685-4027-dc04-0e73c1d7e41d"
      },
      "source": [
        "\n",
        "input_layer = reconstructed_model.layers[0]\n",
        "encoder = reconstructed_model.get_layer(\"dense_2\")\n",
        "decoder = reconstructed_model.get_layer(\"decoded_mean\")\n",
        "\n",
        "get_encoder_output = K.function([input_layer.input],[encoder.output])\n",
        "get_encoder_output = get_encoder_output([X_test])[0]\n",
        "\n",
        "get_decoder_output = K.function([encoder.output],[decoder.output])\n",
        "get_decoder_output = get_decoder_output([get_encoder_output])[0] \n",
        "\n",
        "output_shape = get_decoder_output.shape\n",
        "\n",
        "ag_output = np.argmax(get_decoder_output, axis=2)\n",
        "\n",
        "\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "# step 2: reverse word index to map integer indexes to their respective words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Step 3: decode the review, mapping integer indices to words\n",
        "#\n",
        "# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\"\n",
        "\n",
        "# decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[10]])\n",
        "final_output = []\n",
        "for i  in  range(len(ag_output)):\n",
        "    f_output = ' '.join([reverse_word_index.get(i - 3, '?') for i in ag_output[i]])\n",
        "    final_output.append(f_output)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=================\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2]\n",
            "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WszfEY0qJOS",
        "outputId": "c37309b7-90cf-4e9f-cd80-dc1740e7d775"
      },
      "source": [
        "print(get_encoder_output.shape)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpBZG3Sx398v"
      },
      "source": [
        "reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/adverserial/rnn_ae-03.h5\", compile=False)\n",
        "c\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "Cc0kwM7XGGKg",
        "outputId": "e4e1a258-4f43-40ec-9c4e-67ecb9a84db5"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# from model import VAE\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "disable_eager_execution()\n",
        "\n",
        "# import tensorflow as tf\n",
        "# tf.config.experimental_run_functions_eagerly(True)\n",
        "\n",
        "MAX_LENGTH = 300\n",
        "NUM_WORDS = 1000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
        "print(\"Number of words:\")\n",
        "print(len(np.unique(np.hstack(X_train))))\n",
        "\n",
        "print(\"Training data\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"Training data\")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_LENGTH)\n",
        "\n",
        "\n",
        "train_indices = np.random.choice(np.arange(X_train.shape[0]), 2000, replace=False)\n",
        "test_indices = np.random.choice(np.arange(X_test.shape[0]), 1000, replace=False)\n",
        "\n",
        "X_train = X_train[train_indices]\n",
        "y_train = y_train[train_indices]\n",
        "\n",
        "X_test = X_test[test_indices]\n",
        "y_test = y_test[test_indices]\n",
        "\n",
        "\n",
        "\n",
        "temp = np.zeros((X_train.shape[0], MAX_LENGTH, NUM_WORDS))\n",
        "temp[np.expand_dims(np.arange(X_train.shape[0]), axis=0).reshape(X_train.shape[0], 1), np.repeat(np.array([np.arange(MAX_LENGTH)]), X_train.shape[0], axis=0), X_train] = 1\n",
        "\n",
        "X_train_one_hot = temp\n",
        "\n",
        "temp = np.zeros((X_test.shape[0], MAX_LENGTH, NUM_WORDS))\n",
        "temp[np.expand_dims(np.arange(X_test.shape[0]), axis=0).reshape(X_test.shape[0], 1), np.repeat(np.array([np.arange(MAX_LENGTH)]), X_test.shape[0], axis=0), X_test] = 1\n",
        "\n",
        "x_test_one_hot = temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of words:\n",
            "88585\n",
            "Training data\n",
            "(25000,)\n",
            "(25000,)\n",
            "Training data\n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cffc134e9f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mX_train_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1512 is out of bounds for axis 2 with size 1000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQd0FaLKLGU6"
      },
      "source": [
        "# Embedding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMkf76mfLLYm"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "# the first layer is the embedding layer. \n",
        "# we indicate the number of possible words, \n",
        "# the dimension of the embedding space, \n",
        "# and the maximum size of the text. \n",
        "model.add(keras.layers.Embedding(len(vocabulary), 2, input_length=256))\n",
        "\n",
        "# the output of the embedding is multidimensional, \n",
        "# with shape (256, 2)\n",
        "# for each word, we obtain two values, \n",
        "# the x and y coordinates\n",
        "# we flatten this output to be able to \n",
        "# use it in a dense layer\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# dropout regularization\n",
        "model.add(keras.layers.Dropout(rate=0.5))\n",
        "\n",
        "# small dense layer. It's role is to analyze \n",
        "# the distribution of points from embedding\n",
        "model.add(keras.layers.Dense(5))\n",
        "\n",
        "# final neuron, with sigmoid activation \n",
        "# for binary classification\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0ilQLzeBnBn"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htLKDABWBokc",
        "outputId": "bebfa5e1-e8fe-463c-c980-18f109140301"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYmvGHs0L7HE",
        "outputId": "47d65d48-f462-405e-945e-dadeb2e3d433"
      },
      "source": [
        "# print(clf.predict(X_test))\n",
        "print(clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwzDU4_CL0sL"
      },
      "source": [
        "w = clf.coef_[0]\n",
        "print(w)\n",
        "\n",
        "a = -w[0] / w[1]\n",
        "\n",
        "xx = np.linspace(0,12)\n",
        "yy = a * xx - clf.intercept_[0] / w[1]\n",
        "\n",
        "h0 = plt.plot(xx, yy, 'k-', label=\"non weighted div\")\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c = y)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ik1zk0jPr7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1bd373-03c8-417e-89a8-c1c40f1807fe"
      },
      "source": [
        "# step 1: load the dictionary mappings from word to integer index\n",
        "\n",
        "from keras.datasets import imdb\n",
        "word_index = imdb.get_word_index() \n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
        "\n",
        "# step 2: reverse word index to map integer indexes to their respective words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Step 3: decode the review, mapping integer indices to words\n",
        "#\n",
        "# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\"\n",
        "\n",
        "# decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[10]])\n",
        "train_sentences = []\n",
        "test_sentences = []\n",
        "print(X_train.shape)\n",
        "for i  in  range(len(X_train)):\n",
        "  decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in X_train[i]])\n",
        "  train_sentences.append(decoded_review)\n",
        "for i  in  range(len(X_test)):\n",
        "  decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in X_test[i]])\n",
        "  test_sentences.append(decoded_review)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
            " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
            " ...\n",
            " list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459])\n",
            " list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23])\n",
            " list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouH-Lm0kM1tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48a46f3-66ae-4e51-cec9-ac227854269c"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "kf = KFold(10)\n",
        "test_accuracy = []\n",
        "train_accuracy = []\n",
        "fold = 0\n",
        "print(len(train_sentences))\n",
        "print(len(test_sentences))\n",
        "X = np.concatenate((train_sentences, test_sentences), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "print(X.shape)\n",
        "print(X[0])\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "    vect = TfidfVectorizer()\n",
        "    X_train_tfidf = vect.fit_transform(X_train)\n",
        "    X_test_tfidf = vect.fit_transform(X_test)\n",
        "        \n",
        "    \n",
        "    text_clf = Pipeline([(\"tfidf\", TfidfVectorizer(sublinear_tf=True)),\n",
        "                    (\"svc\", LinearSVC())])\n",
        "    \n",
        "    text_clf.fit(X_train, y_train)\n",
        "\n",
        "    text_clf.predict(X_test)\n",
        "    train_acc = text_clf.score(X_train, y_train)\n",
        "\n",
        "    # test_acc = text_clf.score(X_test, y_test)\n",
        "    \n",
        "    # test_accuracy.append(test_acc)\n",
        "    train_accuracy.append(train_acc)\n",
        "    # print ('[INFO]\\tFold %d Accuracy: %f' % (fold, test_acc))\n",
        "    print ('[INFO]\\tFold %d Accuracy: %f' % (fold, train_acc))\n",
        "\n",
        "    fold += 1\n",
        "    \n",
        "# avgAccuracy_test = sum(test_accuracy) / fold\n",
        "avgAccuracy_train = sum(train_accuracy) / fold\n",
        "# print ('[INFO]\\tTest_Accuracy: %f' % avgAccuracy_test  ) \n",
        "print ('[INFO]\\tTrain_Accuracy: %f' % avgAccuracy_train  ) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "25000\n",
            "(50000,)\n",
            "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "[INFO]\tFold 0 Accuracy: 0.985778\n",
            "[INFO]\tFold 1 Accuracy: 0.985533\n",
            "[INFO]\tFold 2 Accuracy: 0.985356\n",
            "[INFO]\tFold 3 Accuracy: 0.985911\n",
            "[INFO]\tFold 4 Accuracy: 0.985733\n",
            "[INFO]\tFold 5 Accuracy: 0.985822\n",
            "[INFO]\tFold 6 Accuracy: 0.985711\n",
            "[INFO]\tFold 7 Accuracy: 0.985778\n",
            "[INFO]\tFold 8 Accuracy: 0.985822\n",
            "[INFO]\tFold 9 Accuracy: 0.986578\n",
            "[INFO]\tTrain_Accuracy: 0.985802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "JdpHtsZatbwg",
        "outputId": "14fdfc92-355d-4bb9-e074-ef95e7601d03"
      },
      "source": [
        "Auto_accuracy = [0.5315, 0.5175, 0.5030, 0.5030, 0.5240, 0.5230, 0.5125, 0.5050, 0.5120, 0.5095]\n",
        "Auto_loss = [0.6912, 0.8198, 0.6973, 0.6938, 0.6967, 0.6936, 0.6953, 0.6933, 0.6933, 0.6931]\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "# plotting the points  \n",
        "Epochs = np.arange(start=0, stop=10, step=1)\n",
        "plt.plot(Epochs, Auto_accuracy) \n",
        "\n",
        "  \n",
        "# naming the x axis \n",
        "plt.xlabel('epochs') \n",
        "# naming the y axis \n",
        "plt.ylabel('accuracy') \n",
        "\n",
        "  \n",
        "# function to show the plot \n",
        "plt.show() \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myvqXLcEf03b"
      },
      "source": [
        "# CNN\n",
        "\n",
        "https://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRANn4QKect5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0cbee0-5303-4688-b302-0147eb80cd12"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "# pad dataset to a maximum review length in words\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 250)               2000250   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 2,163,605\n",
            "Trainable params: 2,163,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "196/196 - 3s - loss: 0.4210 - accuracy: 0.7835 - val_loss: 0.2872 - val_accuracy: 0.8802\n",
            "Epoch 2/2\n",
            "196/196 - 3s - loss: 0.2073 - accuracy: 0.9194 - val_loss: 0.2738 - val_accuracy: 0.8850\n",
            "Accuracy: 88.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwCKbPkDnG42"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6iKvVCTnJeQ",
        "outputId": "4b96b254-a81c-4717-bbdc-cb5c937ac965"
      },
      "source": [
        "\n",
        "# MLP for the IMDB problem\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,160,501\n",
            "Trainable params: 4,160,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "196/196 - 6s - loss: 0.5057 - accuracy: 0.7216 - val_loss: 0.3115 - val_accuracy: 0.8667\n",
            "Epoch 2/2\n",
            "196/196 - 2s - loss: 0.1943 - accuracy: 0.9273 - val_loss: 0.3060 - val_accuracy: 0.8731\n",
            "Accuracy: 87.31%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKbKF400i76J"
      },
      "source": [
        "# TEST MODEL: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItEVYG3eigMd",
        "outputId": "c31457ec-3833-40cc-b673-e9f4a58a9115"
      },
      "source": [
        "%pip install hickle\n",
        "import keras\n",
        "import hickle as hkl\n",
        "from keras.datasets import imdb\n",
        "from keras import objectives, backend as K\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "MAX_LENGTH = 200\n",
        "NUM_WORDS = 2000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
        "\n",
        "import hickle as hkl\n",
        "\n",
        "# data = {'xtrain': X_train, 'xtest': X_test,'ytrain': y_train,'ytest':y_test}\n",
        "# hkl.dump(data,'data.hkl')\n",
        "# array_hkl = hkl.load('data.hkl')\n",
        "# X_train = array_hkl['xtrain']\n",
        "# X_test = array_hkl['xtest']\n",
        "# y_train = array_hkl['ytrain']\n",
        "# y_test = array_hkl['ytest']\n",
        "\n",
        "# X_train = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
        "\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_LENGTH)\n",
        "X_test = X_test[:10000]\n",
        "y_test = y_test[:10000]\n",
        "# train_indices = np.random.choice(np.arange(X_train.shape[0]), 20000, replace=False)\n",
        "# test_indices = np.random.choice(np.arange(X_test.shape[0]), 3000, replace=False)\n",
        "\n",
        "# X_train = X_train[train_indices]\n",
        "# y_train = y_train[train_indices]\n",
        "\n",
        "# X_test = X_test[test_indices]\n",
        "# y_test = y_test[test_indices]\n",
        "\n",
        "data = {'xtest': X_test, 'ytest':y_test}\n",
        "hkl.dump(data,'data.hkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hickle in /usr/local/lib/python3.7/dist-packages (4.0.4)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.19.5)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.15.0)\n",
            "Requirement already satisfied: h5py<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (2.10.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V54LvYC_lq8B"
      },
      "source": [
        "# LIME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "id": "2uDkri1e1ne2",
        "outputId": "23c8c9dd-65cd-4315-d0a8-f1735e28e57f"
      },
      "source": [
        "%pip install lime\n",
        "from lime import lime_text\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "%pip install hickle\n",
        "import keras\n",
        "import hickle as hkl\n",
        "from keras.datasets import imdb\n",
        "from keras import objectives, backend as K\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "filename = '/content/drive/MyDrive/MLprj/naive_model.sav'\n",
        "\n",
        "def get_naive_model():\n",
        "    # load the model from disk\n",
        "    loaded_model = pickle.load(open(filename, 'rb'))\n",
        "    return loaded_model\n",
        "\n",
        "clf = get_naive_model()\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "        lowercase=True, stop_words=None,\n",
        "        max_df=1.0, min_df=1, max_features=None,  binary=True\n",
        "      )\n",
        "\n",
        "# X = vectorizer.fit_transform(niave_total_data).toarray()\n",
        "\n",
        "# X_train = X[0:10000, :]\n",
        "# X_test = X[10000:, :]\n",
        "\n",
        "# feature_names = vectorizer.get_feature_names()\n",
        "\n",
        "\n",
        "# c = make_pipeline(vectorize_sequences, clf)\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=[ 'negative', 'positive'])\n",
        "\n",
        "# original = \"well sorry for the mistake on the one line ? run people run this movie is an horror imagine gary ? in another low budget movie with an incredibly bad ? here's that a nightmare no well yes it is ? run i give it out of\"\n",
        "\n",
        "# noisy = \"well sorry for the mistake on the one line ? runs people run this movie is an horror imagine gary you in person low budget movie led an incredibly bad ? here's that a nightmare did well yes the is ? run i give it out of\"\n",
        "\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "        lowercase=True, stop_words=None,\n",
        "        max_df=1.0, min_df=1, max_features=None,  binary=True\n",
        "      )\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 2000) \n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "gan_test_data = []\n",
        "Y_final = []\n",
        "for i  in  range(len(train_data)):\n",
        "     decoded_review = \"\"\n",
        "     for j in train_data[i]:\n",
        "        decoded_review += reverse_word_index.get(j - 3, '?') + \" \"\n",
        "     gan_test_data.append(decoded_review)\n",
        "     Y_final.append(train_labels[i])\n",
        "for i  in  range(len(test_data[10000:])):\n",
        "     decoded_review = \"\"\n",
        "     for j in train_data[i]:\n",
        "        decoded_review += reverse_word_index.get(j - 3, '?') + \" \"\n",
        "     gan_test_data.append(decoded_review)\n",
        "     Y_final.append(test_labels[i])\n",
        "\n",
        "for i in range(len(gan_test_data)): \n",
        "    if \"well sorry for the mistake on the one line\" in gan_test_data[i]: \n",
        "        print(Y_final[i])\n",
        "        print(gan_test_data[i])\n",
        "\n",
        "X_final = vectorizer.fit_transform(gan_test_data).toarray()\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "\n",
        "\n",
        "clf = BernoulliNB(binarize=0.0)\n",
        "\n",
        "clf.fit(X_final, Y_final)\n",
        "\n",
        "\n",
        "c = make_pipeline(vectorizer, clf)\n",
        "\n",
        "\n",
        "\n",
        "# original = \"well sorry for the mistake on the one line ? run people run this movie is an horror imagine gary ? in another low budget movie with an incredibly bad ? here's that a nightmare no well yes it is ? run i give it out of\"\n",
        "\n",
        "# noisy = \"well sorry for the mistake on the one line ? runs people run this movie is an horror imagine gary you in person low budget movie led an incredibly bad ? here's that a nightmare did well yes the is ? run i give it out of\"\n",
        "\n",
        "# original = \"original beautiful movie the acting is great the ? ? ? are superb paris at its best but then the real paris not the famous ? and the music will do also a brilliant very ? which i just very much love br br the best french movie here's seen and french cinema is very good\"\n",
        "# noisy = \"original inspired movie one acting the battle battle fat ? ? are excellent paris at its best but finally the real paris not one famous black and normal music will do by a inspired extremely ? is i just though much inspired br br one best french movie here's seen and french cinema is very success\"\n",
        "\n",
        "\n",
        "original = \"i see ? of student films this is ? james ? is a fantastic director he moves the camera tells the story and uses music in a way that is far ? for his years no wonder he got a feature from this film br br\"\n",
        "noisy = \"i see ? of teacher movies the is ? c ? is a fantastic director gets makes normal camera tells the story and uses music normal a way can is situations fat for his years no wonder he getting a feature from makes film br br\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? is great you totally believe his character and here's scary as hell i spent half the movie ? my eyes the other half on the edge of my ? here's cool to see something this ? and ? that here's all blood and ? but it did give me bad dreams br br basically this is a great movie see it the first chance you get\"\n",
        "noisy =\"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? the battle you totally find his character led fat ugly can hell you battle half the hollywood america his fat the situations led began normal edge of his black fat fat can see something battle ? food you that delivers all black battle ? but fat did give you battle dreams fat br basically can is battle battle movie see the normal first chance ? get\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this little two person movie is actually much bigger than it looks it has so many ? here's watched it over and over and always pick up on something new i am ? at the depth of the acting and i feel if this movie had gotten ? release that there would be no question that alan ? is a major star\"\n",
        "noisy = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? can little two person soap is can much situations battle it looks the led so situations ? fat watched the over and over by never fat bed hour what new never am you at the depth the the acted food i situations if this movie had getting you release that there if though battle question that alan you is a major star\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? funny yes a ? classic to watch ? turn green is always a treat and it brings us back to the days when cartoon ? was ? and ? for the adult mind br br loved it\"\n",
        "noisy = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? funny yes a you classic to watch ? turn green is always a treat and it brings us back to the days when cartoon ? was ? and ? for the adult mind br br loved it\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this is the best movie i have ever seen and i love it very much is is so sad and loving i could watch this movie over and over again when i first seen it on disney channel i was like i would love to see this movie again i would love to watch this movie ? and i recommend it to anyone this is really a good movie to anyone who has not seen this movie and is thinking about it they better go and see it because it is really good i love the part when the boy found out about the girl and from then on i was just all into this movie if i could watch two movies ? it would be this one and ? those are my two favorite movies i really love them\"\n",
        "noisy = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? the is the best movie i have ever seen by i love can view much part is changed sad led loving i could america the hollywood over and over again when i first seen the on disney channel i was like i would love the see the movie again i would love to watch this hollywood ? and i recommend it the anyone this is really a good movie to anyone who has not seen the movie and part thinking about it they better go and see it though it the think good i love the normal came the boy found out about the girl and from finally on i was just all into this movie if i could watch two hollywood ? it if be this the well black those are my two favorite films i really love them\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? i watched this film many years ago on tv and ? it from there i could never really understand why my own mother was ? watching it it was because i was so young at the time i have just sat and watched this film again i now have 2 children of my own and i had to try and fight the tears back but that here's happen i was ? through most of the film it just to show how different you feel when you have children of your own such an amazing family such a heart ? film truly wonderful someone has said about 8 still living any more news are you all still in touch i would love to know ? by the film all over\"\n",
        "noisy = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? i watching the film many years ago on television and ? it began there never could never really understand why my own mother was ? watching it the was because i was so young at the time i have just sat and watched this film again i now have 3 children of my own and i had to try and bring one tears back came that here's happen i was ? through most of the film it came to show what different you feel when you have children of your own created an amazing family such the heart ? film truly wonderful someone problem said about 9 still living any led news are you all still in touch never would love to know ? by the film all over\"\n",
        "\n",
        "original = \"in my opinion this is the best ? stone flick probably more because of ? than anything else ? stuff full of ? from the first moment to its dark ending\"\n",
        "noisy = \"in my opinion this is one best ? stone flick probably more battle of ? than anything else ? stuff the of ? from the first moment to its dark ending\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? original beautiful movie the acting is great the ? ? ? are superb paris at its best but then the real paris not the famous ? and the music will do also a brilliant very ? which i just very much love br br the best french movie here's seen and french cinema is very good\"\n",
        "noisy = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? original beautiful movie one acting is battle the ? ? you are superb paris at its best but finally the real paris can the famous ? and the music will do also a brilliant very ? which never just very much love br br one won french movie here's seen and french cinema is very good\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this is one of the most touching films i had ever watched no movie has ? me the way this one did this is a great film and you have to see for yourself here's normally ? with these ? story movies but this one did it for me i was in tears at the end here's ? for the friendship that is portrayed in this movie if i can give this movie a ? stars i could\"\n",
        "noisy = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this is one of the most touching films i without ever watched no hollywood has ? me one way this one did this is a great film and ? have to see for yourself delivers normally ? came these ? story movies but this one did it for me i was in tears at one end here's ? for the friendship that is portrayed in the movie did i can give this movie a ? stars i could\"\n",
        "\n",
        "\n",
        "original = \"can to some people look a bit long but here's one of rare real adventure film it could be compare to with a bit of ? you must see it\"\n",
        "noisy = \"can to some people look a bit long but here's one the rare real adventure film it could be compare to with a bit natural ? you can see it\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this was the very first ? fu movie that i have ever seen the ? is not the greatest but ? better than some that i had seen the plot is much better than some that are made today it is ? at times but that is what gives it that special ? academy award material is it not but if you like to watch fights and a decent story this is for you\"\n",
        "noisy = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this person the very first you fu movie that never have ever seen the ? the not the greatest but ? better than some that i had seen the plot is much better than some that many made today it is ? at times but that is what gives it that special ? academy award created is it can but if you like to watch fights and a decent story makes is for you\"\n",
        "print(len(original))\n",
        "exp = explainer.explain_instance( original, c.predict_proba, num_features=20)\n",
        "\n",
        "print('Probability =', c.predict_proba([original]))\n",
        "print('True class: %s' % 1)\n",
        "exp.as_list()\n",
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.7/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.5.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Requirement already satisfied: hickle in /usr/local/lib/python3.7/dist-packages (4.0.4)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.19.5)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.15.0)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (0.3.3)\n",
            "Requirement already satisfied: h5py<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (2.10.0)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "? well sorry for the mistake on the one line ? run people run this movie is an horror imagine gary ? in another low budget movie with an incredibly bad ? isn't that a nightmare no well yes it is ? run i give it out of \n",
            "585\n",
            "Probability = [[0.15816567 0.84183433]]\n",
            "True class: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "52s8QyCwswU5",
        "outputId": "a0419e8f-314f-460b-92bd-a939c0ab207d"
      },
      "source": [
        "original = \"this was the very first ? fu movie that i have ever seen the ? is not the greatest but ? better than some that i had seen the plot is much better than some that are made today it is ? at times but that is what gives it that special ? academy award material is it not but if you like to watch fights and a decent story this is for you\"\n",
        "noisy = \"this person the very first you fu movie that never have ever seen the ? the not the greatest but ? better than some that i had seen the plot is much better than some that many made today it is ? at times but that is what gives it that special ? academy award created is it can but if you like to watch fights and a decent story makes is for you\"\n",
        "\n",
        "original = \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? i first watched this movie in ? film festival back in ? it was so good i took couple of friends with me and went to see it again the same week the characters are very well played and the humor here and there is amazing it sure is a very powerful gay movie some scenes make you feel here's watching an episode of friends with much more ? lines i guess here's put it in my ? and watch it again ?\"\n",
        "noisy = \" ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? i first watched this hollywood in ? film festival back normal ? it was can good i took began of friends with me and went to see it time the same week the characters are very well played and one humor here and there is amazing it sure is a clearly powerful gay movie some scenes make you feel here's watching an episode of lady with much more ? lines i guess here's put it in your you and watch it again ?\"\n",
        "\n",
        "original = \"can to some people look a bit long but here's one of rare real adventure film it could be compare to with a bit of ? you must see it\"\n",
        "noisy = \"can to some people look a bit long but here's one the rare real adventure film it could be compare to with a bit natural ? you can see it\"\n",
        "\n",
        "\n",
        "original = \"original beautiful movie the acting is great the ? ? ? are superb paris at its best but then the real paris not the famous ? and the music will do also a brilliant very ? which i just very much love br br the best french movie here's seen and french cinema is very good\"\n",
        "noisy = \"original inspired movie one acting the battle battle fat ? ? are excellent paris at its best but finally the real paris not one famous black and normal music will do by a inspired extremely ? is i just though much inspired br br one best french movie here's seen and french cinema is very success\"\n",
        "\n",
        "\n",
        "original = \"i see ? of student films this is ? james ? is a good director he moves the camera tells the story and uses music in a way that is far ? for his years no wonder he got a feature from this film br br\"\n",
        "noisy = \"i see ? of teacher movies the is ? c ? is a good director gets makes normal camera tells the story and uses music normal a way can is situations fat for this years no wonder he getting a thing from makes film br br\"\n",
        "\n",
        "print(len(original))\n",
        "exp = explainer.explain_instance( original, c.predict_proba, num_features=20)\n",
        "\n",
        "print('Probability =', c.predict_proba([original]))\n",
        "print('True class: %s' % 1)\n",
        "exp.as_list()\n",
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "197\n",
            "Probability = [[0.03416688 0.96583312]]\n",
            "True class: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us_T2zFLGSeO"
      },
      "source": [
        "0.6589 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "eo6eCuATR3e0",
        "outputId": "f73ac987-b92b-463f-be15-bf54a7abffd7"
      },
      "source": [
        "exp = explainer.explain_instance(noisy , c.predict_proba, num_features=20)\n",
        "print('Probability =', c.predict_proba([noisy]))\n",
        "exp.as_list()\n",
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()\n",
        "print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability = [[0.15141174 0.84858826]]\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4f89l_UlvYT"
      },
      "source": [
        "# Plot VAE result\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "aUp3b59Dl12_",
        "outputId": "7315e08d-2851-47d3-c63d-770a8623c3f6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f = open(\"/content/drive/MyDrive/MLprj/AE-3.out\", \"r\")\n",
        "lines = f.read().split(\"decoded_mean_accuracy: \")\n",
        "acc = []\n",
        "index = []\n",
        "for i in range(1, 40000):\n",
        "      acc.append(float(lines[i].split(\" - \")[0])*100)\n",
        "      index.append(i)\n",
        "      \n",
        "plt.plot(index, acc)\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"VAE Accuracy\")\n",
        "plt.show()\n",
        "print(max(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEGCAYAAACNaZVuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xcdb3/8ddnd9N7IwkpbEJCCaElS+hBCGIoKqI0W9QgFrxX8aoE9f7Ecq+AcsWLcAUBgwoXMOgFpZdQA6QRUkglCSkkJCHZ9Gz9/P44Zzazu7O7M7PT5/18PPLImTNz5vvZs7Of+Z7P+Z7vMXdHRESKS0m2AxARkcxT8hcRKUJK/iIiRUjJX0SkCCn5i4gUobJsBxCP/v37e3l5ebbDEBHJK/Pmzdvm7gNiPZcXyb+8vJy5c+dmOwwRkbxiZu+19JzKPiIiRUjJX0SkCCn5i4gUISV/EZEipOQvIlKElPxFRIqQkr+ISBFS8i8wC9ZXsnjjzmyHISI5Li8u8pL4XXz7awCsvfHCLEciIrlMPX8RkSKk5C8iUoSU/EVEipCSv4hIEVLyl5So3FfNv//fYqpq67IdiojEQclfUuLmp5fz5zfe4+/zN2Y7FBGJg5K/pER9vQPgWY4jUW+u/pDpr63JdhgiGadx/pJSnmfZ//K73gDgS6ePyHIkIpmlnr+khFm2IxCRRCj5S0p53hV+RIqTkr+kiLr+IvlEyV9EpAgp+YuIFCElf0mpfBvtI1KslPwlJTTaJzE1dfVc+9AC1mzbm+1QpEilPfmbWamZvWVm/wwfjzCzN81slZk9ZGYd0x2DSK55a10lf39rIz+Y8Xa2Q5EilYme/7eBpVGPbwJ+4+6jgB3A1AzEIBmSbNXn5RVbqdxXndS2izfuLLoe9LoP97FzX022w5A8ltbkb2ZDgQuBu8PHBpwDzAhfch9wcTpjkMxoT9Vn5/4avnjvbK7+07yktr/otlc5+9cvtiOC/DPxVzOZ9F8vZTsMyWPp7vnfCvwAqA8f9wMq3b02fLwBGJLmGCTHVdcGH493t+7JciT5ZdueqmyHIHksbcnfzC4Ctrh7Ut05M7vazOaa2dytW7emOLrc5e788O+LmLN2e7ZDyZjIVcE6aSySOens+Z8OfMLM1gIPEpR7fgv0NrPIhHJDgZhzALv7Xe5e4e4VAwYMSGOYuaXe4YE313H5na9nO5TktGusZ35l/627q/jV08saZjTNFzOXbeEL97yJ59m43EvueI2H567PdhgFI23J392vd/eh7l4OXAG84O6fA2YCnwlfNgV4NF0xSOa0q9fuKXiPLLj+bwu5fea7vL76w2yHkpAvT5/DKyu3UVOXX8l//rpKfjBjYcbb3b63mpdXFF71IRvj/K8DvmtmqwjOAdyThRgkTZJJJ5GOc57lfg7UBOcq6vOsBx2x+4BGC8Xj83e/yRfvnd1wbqpQZCT5u/uL7n5RuLza3Se4+yh3v9TdC+6sVW1dPffNWktNXeIflnw7FI+wdqTuSM0/mf0lievZOai65lm1KmtWbtkNFN6MtbrCNw0emL2Onzy2hHtfza87RM1ctoXzf/sKtRlOwpHvux1ZHLf+zvu7stZ2tnx5+uxsh5AXvOHINN+OTVun5J8Gu/YHSWxXEofVlsXC9/dnvM3STbvYnuTFVsmK7k/VZak7um77vqy0mw27DgQjrRdvzM8vvHw7wZ6rlPzTKJkKTqTsk43P97Y91WEMmW03utR1+A+fyGzjoVufW5GVdturvWXCRLffV13L/HU7km5vb1Vt2y9qQzLXN8xft4NZ725rd9vJWJ+jHQsl/wLVnqTw9vrKdrSbmW1Sbdnm3Vx139yEtokcpaz8IHsXp7V36OM375+f0OuvfWgBl9wxi/Jpj7Nsc2JHDm+vr+SYnzzNU4s3JbRdUy8lMfLmkjtm8dk/vJlUe5GPZzIH5U8s2sSZN8/kxeVbkmo7nXQD9wJVVVtP5w6lSW1buT+ZclVSTcXk7kmVv8qnPd7o8YpfnE/Hsvj7N88t/QAIppsoLTGqaup4aslmzj16IAN7dm72+sgQz5/98x2+ckZyN4DfmcS+jnbdI4u47pFFAKy98cKEt39y8Wbq652Skvj298INOxuWJ9/6SkJtLtwQdCpeWbmNyWMHJxZolO/PWMhf3niP7553JMcP7cWeqlpmr9nOnqpaXly+lReWBYn2a2eNpGuHMj5/yvCGbSOfkUjcv3xiKXe+vJp5Pz6Xft07xWwv0pH6+G2vMnZIL3596fFxxxrpSC3dtJuPHHlI4j9sGin5p0Ekce0+kPghbqo6wZNueYnXpp2T1LYL1ldyWcUw1m7bS9eOpTz29vt071TG5LGD6N219UlYEz3iqK6tZ2914/004vonmHb+Udz45LJG6886YgC/ufwEenQuo0Np20n9iB8/yR2fG0eJGR87ZiALN+zkk7e/xnfOHU3vLh04dmjvZts0/QIB+NHfFwNw4yXHsubDvRzevzu9unZo9rotuw9w81PLmTFvA3/75mlccsesZq+ZeMQAXl6xlR7hiJsVH+yhfNrjnDm6P6+sjF2WOGVkX7p1LOP5ZVu4csKwFs+LPDh7HVdMGN5o3Zpte7nt+ZW8vaGSKaeV8+aa5leOj4wqtX3r7FEcOagHowd2p1+3TgzoESTEjZX7eX7pB2zaeaDRtrH2V1M/+fgYps9ay3sfBuWPeL/X6+udjZX7+e/nVzYr9by9YSdT7m39hPWdL60G4DcxSnrl0x6nf/dODe87/hfPAdC/eydKS+C6yUcxpHcXXli+paEEu2zzbpZt3s2MeRv4v2tOZ/veKn7x+FJWbw0mFbzqjBFU7q9hcK/OrN++jzlrd7Cxcn+jn7m2rp4/v/EeTyzaxOBeXbjwuMGcMKw3A3t2ZveBGmYu38ruAzXs3F/DX15/j/d3HmDpzybTpWNyHbnWWD4MLayoqPC5cxM7JM+ma+6fz+OLgkPbRHtjNXX1jP7RkwA88o1TGdanK507ltKzc/NkE0v0H+PaGy+ktq6ee8JRRzc9tSzmuYSKw/pwwrDe3J3E6KSR/bsBsDqcVfPfLxrDrv01fHvSaEpKjPnrdjRLgpdXDOOhdpYrjhjYnRUf7KFTWQlVeTb+umNZSU6MGX/o6lO4/K43Mt7ujy44mq9OHBnzufXb91FTV8/vX3qXh+duSOh9h/TuwmmH9+OCYwdz7NBe1NTV8/q7H/LEok08t7Tlskvfbh3Zvje9gxxOGdmXB68+Na4vy6ae/PaZHD24Z1Ltmtk8d6+I+ZySf+p99U9zefadoISw9sYLqamrZ19VHRsq93HMob2AoIf8zDsfsH77PjqWlTD9tbWU9+/WcMja1LXnHtGoBzOkdxdGDujGW+sqmXhEf55Z8gHjD+sTs2eXTueNGUhZqfHEos1Jv8dRg3qwbPPumM89cNXJnHp4P1Zu2cNTizfz0Jz1bKzcT1mJUVvvfGb8UGbMO5gkpp1/FF8/63BqwmstfvH4wdnE+3XrSN9uHfny6SPo3KGkUVK490sVHD24J+s+3MdxQ3s362kt37ybTTv3s2HHfkYd0p1HF2zkf2e3/gX2/Y8dyTVnj2JPVS1dO5Q2Kq1srNzP6Te+0Gybr5w+gismDKNyXw3b91Yzeewg5q/bQakZxw7pRXVdPWUlxqiwgwBwx+fGtVi779qxlHHD+3BpxVCOH9obMzjrVy8CwWdz5PWPxzW4oEenMr5x9uG8uHwrs9dsZ+SAbg093t9/fhx/m7+RT48fyvC+Xdl9oJYJI/oCMHvNdurqndEDu7N++z4+dccs7plSwQ3/WML67fvbbPfLp5dz2uH9+eiYgY1KNomWBqOT7sNfO5XLwulT7vzCeD52zCD2VQclo/7dOzFn7XZOGdmXyn017DpQw7UPtX7PhQeuOpmxQ3vx0vKtjOjfjS27D1DerxvD+3blL2+8xw3/eKfN+EoMunUsY9LRh/Dp8UMZe2gvenft0O7Rf60lf5V90qBjVElixQe7Oe83L8e13epW5qRveui6sXJ/wyFlJPHGk/hvvfwERh3SnbFDgi+htdv2MrxvV3bur+HEnz/b6LVfmziS6y84Oq7YZ727rdUTaqv+43xq653XVm1j/GF9GpWPdh+o4dgbngniCY+Umv5xHzGwB0cM7MG/Thrd7L2vOXsUZ//6Rf7vmtM5YVhQyulQWsJVZ47kqjNj9zABLhk3tCEpnHPUQAAG9+oS87VHDurBkYN6NDw+ZWQ/du6vafalt+aXFzT7g+3eqe0/sxKD1b+MfZQ4bnifhuXOJY2/lCL7K9LJWLttLzPmbeCyk4Zx+IDubbbbUpst+WvYG1+9dW+jo9qWaviRLwGA98PP62+eW9Fq4v/48Yfy+ZOHc/LIfi2+Jtmk+ODVpzBhRN9mR+RdO5ZxwbGDm8UMNEr+rR3Jf/z4Q8OlXg3ralv4Zk3m/EyqKfmnQfT4/tYS/xmj+nPZScMY0rsLh/buzOBeXaitq2/Uq4t26+UncPGJQ6ir9+BoorqO3QdqGN63K9v3VtO5QynH/OTpRtvc/tlxXHhcyyfXysOyTZ9ujWv5xxzaM+7E35pXfnA2w/p2BaCsFCYdPbDZa2L9eSTyxz2if7es/DGVlhz8kp/743Pp38IJw1iij7hX/sf5cZ3DaEuH0hJGD+yRkt9bS1Jx05zo6wvOHN2fP089ud3vGa9EBgCkQqzCSi4kflDyT4t57zUfB/3G9ZOY994Ornlgfqt/7GVR6395ybFc2eQEHkBpiVFaUkrnDqX0DZN2rJEKt115YquJvyXRPeh4RX/I1954IVW1dXQsLYkrideFE4z16hLfeY1cET2nT+8EY48e5ZOKxJ9p44Yn9vmIJdZRUrpl+lxL01FUuZL4Qck/5dydfdV1jda9et3ZDOrVmQuPG8yFx8X/y4+V+OOV6DDHaGOSOLlUVdv4Z+5UFv/ohLowiZbGOdwwV0R67/27d2r0pR2PbJ7wPam8D3PWJn+hFkB1CqYAycbV7Bt3tH2eoamencvYdaCWp78zMeFto3/CF7/3kYS3Tycl/xTZvreamcu28G9/bX5yaGifrhmL4/efH8/uAzUZP7z92/yYt2WIS+Ry/fxL/sH/P/vkMQlvG7lu4MQU9KAT9devn9bu9zhxWJ+2X9SKbPWAI2XORBw1qCez125naJ/Y54NaE131SabtdFLybwd351N3zGJ/dR1rP9wbc8jhRUmUXdpj8thB7X6PZDpk7blsP3JSrDTPJvSfeMQAnly8mVGHtH1italDe3fhz1MncOLw9iXRTDt2SC8WbdzJZ8YPzXYoSRk7JPGj2j98sYIlm3bSLY4T9/mksH6aDNm5r4Yf/n1Rw1h+gAnlfbnqzBFMPGIAjy7YyHWPLOLT44Zyy2XxXw2Yz9pzX5BBPTtz5YThfOGUw1IXUAZccdIwJh8zqNnJ8nidOTr/7lDXnltuLsmBmVMTKUdG9OragdMO759Ue7k8lF7JP0Fbdh3g7F+/yN6ouv7r15/TaIhg5PddlmdljIhMR11SYvzykmMz3Gr7mVnSiT9ftWd6413tnMoin33l9OSm/0gnJf8E3PDYEqbPWtvw+C9TT+aM0c17BLn7XZ8+J4/oy8srtnLJiUOyHYpkQDI9/04pOA81Msfq5vlMyT9O/1z4fkPiP/foQ7h7ykktvrahd5SfHf+kRmFENjkkxgRoUjjaU8UobeeQ1mevncghPfLz85WLuUDJP07feuAtoO3ED+2ri+arCeXBVZGnj2r5qkzJf+05qu2S5CyzEaMH9mj7RS1YeMN5eBZG1+ZwyV/JPx53vvRuw3JbiR9gYngi79KKYWmLKZ2S+c6qKO/Lsp9PTnoaaUnMob06M+bQXm2/ME2S6dh075S9z0a8EyOmSy72A5X8W/Dogo3c8swK/jL1ZH4ZTi18w8fHxLXtsL5dc+pKvkxR4s+cWddPykq77Rm9ksu94HTJ5Zu+K/m34AczFlJVW8/EX81sWPelHDxjnw7FVK6S5BTazczTLRf/pvJvUpEseednH8t2CCJZ157BDJE+8CE94p8AL9/l8tGOkn8Loq/W/cTxh9K1Y/EcJGVjzhXJD6kYzDD+sPy6qjkVcvFvSsk/DtFX8ooUs/Zc5JXLveB0yeUfWck/Dg9/7dRshyCSU5Ir+xTfEOiIXPyRlfzjUIyHqcWid4wbsUvL2tOTbc9RQ77K5aOd4ilki8Tw3HfPYtueqmyHkTciQz2TSd8NebB4cv9BOfgzK/m3IdY9Y6Vw9O/eKaHbLxa7SAJPquzTji+OfJXL4/yLuuzz1rodlE97nOmvrWlYV1NX33BzEYBPZWmisrOPzL/pfqUIpKD7nosjX9ItF0tdRd3z/9QdswC44R/v0K1TGa+/+yF/e2tjo/vXZuNXNudH59KzS1H/aiRHta/nH26bsmikPYo2w2zaGdzL84xR/Xl11Ta+P2Nhw3ML1lc2LGfj1oIDiugiGMkv7av5F+9on1xUtMn/lZXbALj+gqOorq3ndy+s4pSR/bjqzBHMWbuDy+58HdAHVSTawZ5/8uP8i+lPSqN9ctAPZiykU1kJYwb3xMy450sHZ+ucMKIvh/bqzPs7D2QxQpHc054EfnBqiGJK/4Fc/JGL8oTv39/aAMCkow9p8YPYnh6OSKGK3Jq0PXP76C8qNxRlz//ah94G4KefGNvia4rxEFWkLXdPqeChOesZ3rdr8m9SRH9UuTy8NW09fzPrbGazzextM1tiZj8N148wszfNbJWZPWRmGb0D9qINOwG4csKwuE6squMvctDIAd25/oKjk6z553ABPM1yMY+ks+xTBZzj7scDJwCTzewU4CbgN+4+CtgBTE1jDM3c/epqunQoZdr5R7f6uly+OEMkHx0s++RgJkyTXP6+S1vy98Ce8GGH8J8D5wAzwvX3ARenK4am9lbV8uSizXxm/FB6dWl9TpdinIdEJK3acS+AfJeLeSStJ3zNrNTMFgBbgGeBd4FKd68NX7IBiHkJrZldbWZzzWzu1q1bUxLP/HU7qK6r59wxA9t8bXsuZhGR5hrG+Wc5jkzK4Y5/epO/u9e5+wnAUGACcFQC297l7hXuXjFgQGqmOnh+6RYAKhKYpbOYPqgi6dSeu4Dlu1z8mTMy1NPdK4GZwKlAbzOLjDIaCmzMRAwA02etBaBbp7YHOeVyrU4kH6nmn1vaTP5mNs/MrjGzhCa1N7MBZtY7XO4CfBRYSvAl8JnwZVOARxMLOTnV4W0ZLzpucJxbaKynSCqV9+sGwNihvbIcSeblYhqJZ5z/5cCXgTlmNhf4I/CMtz1uazBwn5mVEnzJPOzu/zSzd4AHzewXwFvAPcmHH7/lm3cDcP7Y+JJ/ZGLPklw8XkuTR75xGq+sTM35FZGmTj28H89cO5HRh3TPdigZk8ujBttM/u6+CviRmf07cBFwL1BnZn8Efuvu21vYbiFwYoz1qwnq/xl13+trAThiYHwfvN5dOrB9bzWlRZT8xx/WR3ctk7Q6YmCPbIeQHTmYR+K6wtfMjiPo/V8APALcD5wBvEAwhj/n7a0KBhiN6N8trtf/aeoEnl+6hT7dMnoNmogUkFyu+beZ/M1sHlBJUJ6Z5u6Re969aWanpzO4VOpQWsLwvl0pK43vHPfQPl2Zclp5eoMSkaKQe/3++Hr+l4almmbc/ZIUx5M2m3ceYFCvztkOQ0SKSA53/OMa6nlVZNQOgJn1CU/W5pVte6sYoHu1ikgW5GDJP67kf344Th8Ad99BUPvPK9t2V9G/u+r3IpJBOVz0jyf5l5pZQ5c5HLOfV13oqto6dh2opZ96/iKSBbl4YVs8Nf/7gefDoZ0QjPq5L30hpd6WXcE56kE9VfMXkczJ3X5/fOP8bzKzhcCkcNXP3f3p9IaVWpt3Bbdj1AlfEcmGXKz5xzXO392fBJ5Mcyxps31vNQB9NWZfRDIoh0v+cc3tc4qZzTGzPWZWbWZ1ZrYrE8GlSuW+IPn37tr6HP4iIumQgx3/uE74/g64ElgJdAGuAm5PZ1CpVrmvBoDeXdXzF5HMyeW5feK63DWc36c0nJ//j8Dk9IaVWjv311BWYnTrWJrtUESkCOVrzX9feJP1BWZ2M7CJDN0HIFV2HaihR+eypG46LSKSrKvOGMmKD/bwhVPKsx1KM/Ek8S+Er/sWsBcYBnw6nUGl2u4DtfRs4569IiKp1qdbR/7wxQp65eD5xlZ7/uFc/P/p7p8DDgA/zUhUKTZ37Q5q6uqzHYaISM5oNfm7e52ZHWZmHd29OlNBpdrGyv3ZDkFEJKfEU/NfDbxmZo8RlH0AcPf/SltUaXD+2EHZDkFEJGfEk/zfDf+VAHl3G576eseMorp1nIhIW+KZ3iEv6/wRe6trcYcenXPvhIuISLbEcyevmcSYn8jdz0lLRCm260Bw+8YeneOayUJEpCjEkxG/F7XcmWCYZ216wkm9d94PZqJYt31fliMREckd8ZR95jVZ9ZqZzU5TPCnXNbyq94zR/bMciYhI7oin7NM36mEJMB7olbaIUuxATR0A3Tup7CMiEhFPRpxHUPM3gnLPGmBqOoNKpX3VQfLv0kHz+oiIRMRT9hmRiUDSZX/Y8++s5C8i0iCe+fyvMbPeUY/7mNk30xtW6kTKPl01o6eISIN4Jnb7qrtXRh64+w7gq+kLKbUayj5K/iIiDeJJ/qUWNRdyONlb3twVZVM4r0/nMiV/EZGIeE74PgU8ZGZ3ho+/Fq7LCy+v3AZASYnm8hcRiYgn+V8HXA18I3z8LHB32iJKsRH9u7Fxh2b1FBGJFk/y7wL8wd1/Dw1ln05AXlwyW+/O0YPzbj46EZG0iqfm/zzBF0BEF+C59ISTevuq6ujaURd4iYhEiyf5d3b3PZEH4XLX9IWUWlW1dXTqkFe3HBYRSbt4suJeMxsXeWBm44G8KaJX1dbTsVTJX0QkWjz1kO8AfzWz9wmmeBgEXJ7WqFKouq6eDmVK/iIi0eKZ3mGOmR0FHBmuWg70bWWTnFJdW08n9fxFRBqJKyu6ew2wATiZYIz/W21tY2bDzGymmb1jZkvM7Nvh+r5m9qyZrQz/79OeH6AtNXX1dFTPX0SkkVazopl1MbMrwpu3LwJuAX4ODI3jvWuBf3P3McApwDVmNgaYBjzv7qMJRhJNa88P0JbqWiV/EZGmWsyKZvYAsAL4KHAbUA7scPcX3b2+rTd2903uPj9c3g0sBYYAnwTuC192H3Bxe36AtlTX1tNBZR8RkUZay4pjgB0ESXupu9cR416+8TCzcuBE4E1goLtvCp/aDAxsYZurzWyumc3dunVrMs0CwQlf9fxFRBprMSu6+wnAZUAP4DkzexXoYWYxk3VLzKw78AjwHXff1aQNp4UvFHe/y90r3L1iwIABiTTZYE9VLTV1zrz3diS1vYhIoWq1S+zuy9z9J+5+FPBtgjLNHDObFc+bm1kHgsR/v7v/LVz9gZkNDp8fDGxJOvo2LNm4s9H/IiISiLse4u7z3P17wGHEcZI2nAb6HoKS0X9FPfUYMCVcngI8Gn+4iamrDw4q/ufz49PVhIhIXkp40puwVPNyHC89HfgCsMjMFoTrfgjcCDxsZlOB9whKS2nxwrLgoKKqts3z0yIiRSVtM565+6sEVwTHMild7Ubbsa8GgKF9urTxShGR4lLQw2D+8fb7AJSYbuQiIhKttXH+t0Ytf7vJc9PTGFPKfPe8IwD1/EVEmmqt5z8xanlKk+eOS0MsKRc54VtWqp6/iEi01pK/tbCcN2rrguTfoaSgq1siIglr7YRvSTjpWknUcuRLoDTtkaVAbX09Zrp5u4hIU60l/17APA4m/PnpDye1autdvX4RkRhaTP7uXp7BONKitq6eUvX6RUSaSahbbGaHm9m/m9mSdAWUSrX1rpO9IiIxtJn8zexQM7vWzOYAS8Jtrkh7ZCnw5KLN7D5Qm+0wRERyTmvj/K82s5nAi0A/YCqwyd1/6u6LMhRfu/TskrYLmEVE8lpr2fF3wOvAZ919LoCZJTWff7aMHdKLfdV12Q5DRCTntJb8BwOXAreY2SDgYaBDRqISEZG0au1mLh+6++/d/SzgXKCSYC7+pWb2nxmLsD3y6jhFRCRzWqv5325mpwO4+3p3v8XdKwjuwXsgUwG2l+Z0ExFprrXRPiuAX5vZWjO72cxOBHD3Fe7+s8yEJyIi6dBa2ee37n4qcBbwIXCvmS0zs5+Y2eiMRSgiIinX5jh/d3/P3W9y9xOBK4GLgWVpjywFVPIXEYktnou8yszs42Z2P/AksBy4JO2RpYjl54SkIiJp1eJQTzP7KEFP/wJgNvAgcLW7781QbCIikiatjfO/HngA+Dd335GheFIquNe8iIg01dqsnudkMpB00VBPEZHmNNm9iEgRUvIXESlCBZ38VfEXEYmtoJM/5Omd50VE0qzgk7+IiDRX0MlfIz1FRGIr6OQPYBrrKSLSTMEnfxERaU7JX0SkCBV08lfJX0QktoJO/qChniIisRR88hcRkeYKOvlrVk8RkdgKOvkDqvuIiMSQtuRvZvea2RYzWxy1rq+ZPWtmK8P/+6SrfRERaVk6e/7TgclN1k0Dnnf30cDz4WMREcmwtCV/d38Z2N5k9SeB+8Ll+whuBp82qviLiMSW6Zr/QHffFC5vBga29EIzu9rM5prZ3K1btybdoEr+IiLNZe2ErwdDcVrsnLv7Xe5e4e4VAwYMyGBkIiKFL9PJ/wMzGwwQ/r8lra2p7iMiElOmk/9jwJRweQrwaLob1KyeIiLNpXOo5/8CrwNHmtkGM5sK3Ah81MxWAueGj0VEJMPK0vXG7n5lC09NSlebIiISn4K+wtdV9BcRiamgkz9oqKeISCwFn/xFRKQ5JX8RkSJU0MlfMzqLiMRW0MkfQMP8RUSaK/jkLyIizRV08lfZR0QktoJO/gCmwZ4iIs0UfPIXEZHmlPxFRIpQQSd/Te8gIhJbQSd/0FBPEZFYCj75i4hIcwWd/DXUU0QktoJO/iIiEpuSv4hIEVLyFxEpQgWd/FXyFxGJraCTP4BprKeISDMFn/xFRKS5gk7+GuopIhJbQSd/0A3cRURiKfjkLyIizSn5i4gUoQw6tNIAAApiSURBVAJP/ir6i4jEUuDJX7N6iojEUvDJX0REmivo5K+hniIisRV08geVfUREYin45C8iIs0p+YuIFKGCTv4q+YuIxFbQyR/ANMGDiEgzBZ/8RUSkOSV/EZEilJXkb2aTzWy5ma0ys2npasc10F9EJKaMJ38zKwVuB84HxgBXmtmY9LWXrncWEclf2ej5TwBWuftqd68GHgQ+mYU4RESKVlkW2hwCrI96vAE4uemLzOxq4GqA4cOHJ9VQRXlfdh+oTWpbEZFClo3kHxd3vwu4C6CioiKp4v01Z49KaUwiIoUiG2WfjcCwqMdDw3UiIpIh2Uj+c4DRZjbCzDoCVwCPZSEOEZGilfGyj7vXmtm3gKeBUuBed1+S6ThERIpZVmr+7v4E8EQ22hYREV3hKyJSlJT8RUSKkJK/iEgRUvIXESlClg+Tn5nZVuC9JDfvD2xLYTiporgSo7gSo7gSU6hxHebuA2I9kRfJvz3MbK67V2Q7jqYUV2IUV2IUV2KKMS6VfUREipCSv4hIESqG5H9XtgNogeJKjOJKjOJKTNHFVfA1fxERaa4Yev4iItKEkr+ISBEq6OSfqRvFR7W31swWmdkCM5sbrutrZs+a2crw/z7hejOz/w5jW2hm46LeZ0r4+pVmNiXJWO41sy1mtjhqXcpiMbPx4c+6Ktw2rrsltxDXDWa2MdxvC8zsgqjnrg/bWG5mH4taH/N3G04V/ma4/qFw2vC2YhpmZjPN7B0zW2Jm386F/dVKXNneX53NbLaZvR3G9dPW3svMOoWPV4XPlycbb5JxTTezNVH764RwfcY+9+G2pWb2lpn9Mxf2F+5ekP8Ipot+FxgJdATeBsakuc21QP8m624GpoXL04CbwuULgCcBA04B3gzX9wVWh//3CZf7JBHLRGAcsDgdsQCzw9dauO357YjrBuB7MV47Jvy9dQJGhL/P0tZ+t8DDwBXh8u+Bb8QR02BgXLjcA1gRtp3V/dVKXNneXwZ0D5c7AG+GP1vM9wK+Cfw+XL4CeCjZeJOMazrwmRivz9jnPtz2u8ADwD9b2/eZ2l+F3PPPlRvFfxK4L1y+D7g4av2fPPAG0NvMBgMfA5519+3uvgN4FpicaKPu/jKwPR2xhM/1dPc3PPhU/inqvZKJqyWfBB509yp3XwOsIvi9xvzdhr2wc4AZMX7G1mLa5O7zw+XdwFKCe01ndX+1EldLMrW/3N33hA87hP+8lfeK3o8zgElh2wnF2464WpKxz72ZDQUuBO4OH7e27zOyvwo5+ce6UXxrfzip4MAzZjbPghvQAwx0903h8mZgYBvxpTPuVMUyJFxOZYzfCg+977WwvJJEXP2ASnevTTau8BD7RIJeY87sryZxQZb3V1jCWABsIUiO77byXg3th8/vDNtO+d9A07jcPbK//iPcX78xs05N44qz/fb8Hm8FfgDUh49b2/cZ2V+FnPyz4Qx3HwecD1xjZhOjnwx7CzkxtjaXYgH+BzgcOAHYBNySjSDMrDvwCPAdd98V/Vw291eMuLK+v9y9zt1PILgH9wTgqEzHEEvTuMxsLHA9QXwnEZRyrstkTGZ2EbDF3edlst22FHLyz/iN4t19Y/j/FuDvBH8UH4SHi4T/b2kjvnTGnapYNobLKYnR3T8I/2jrgT8Q7Ldk4vqQ4NC9rMn6NplZB4IEe7+7/y1cnfX9FSuuXNhfEe5eCcwETm3lvRraD5/vFbadtr+BqLgmh+Uzd/cq4I8kv7+S/T2eDnzCzNYSlGTOAX5LtvdXWycF8vUfwS0qVxOcGImcBDkmje11A3pELc8iqNX/isYnDW8Oly+k8cmm2X7wZNMaghNNfcLlvknGVE7jE6spi4XmJ74uaEdcg6OWryWoawIcQ+MTXKsJTm61+LsF/krjk2jfjCMeI6jf3tpkfVb3VytxZXt/DQB6h8tdgFeAi1p6L+AaGp/AfDjZeJOMa3DU/rwVuDEbn/tw+49w8IRvdvdXMkklX/4RnM1fQVCP/FGa2xoZ7vS3gSWR9ghqdc8DK4Hnoj5EBtwexrYIqIh6r68QnMxZBXw5yXj+l6AkUENQA5yayliACmBxuM3vCK8WTzKuP4ftLgQeo3Fy+1HYxnKiRla09LsNfw+zw3j/CnSKI6YzCEo6C4EF4b8Lsr2/Wokr2/vrOOCtsP3FwP9r7b2AzuHjVeHzI5ONN8m4Xgj312LgLxwcEZSxz33U9h/hYPLP6v7S9A4iIkWokGv+IiLSAiV/EZEipOQvIlKElPxFRIqQkr+ISBFS8pecYmZuZrdEPf6emd2QoveebmafScV7tdHOpWa21MxmprutJu1+ycx+l8k2JX8p+UuuqQIuMbP+2Q4kWtSVmPGYCnzV3c9OVzwi7aXkL7mmluC+pdc2faJpz93M9oT/f8TMXjKzR81stZndaGafC+d2X2Rmh0e9zblmNtfMVoRzrkQmA/uVmc0JJ//6WtT7vmJmjwHvxIjnyvD9F5vZTeG6/0dwcdY9ZvarGNt8P6qdyHzz5Wa2zMzuD48YZphZ1/C5SRbMAb8onMStU7j+JDObZcHc9bPNrEfYxKFm9pQF89DfHPXzTQ/jXGRmzfatFJ9EejMimXI7sDCSvOJ0PHA0wXTRq4G73X2CBTdA+RfgO+HrygnmdjkcmGlmo4AvAjvd/aQwub5mZs+Erx8HjPVgCt0GZnYocBMwHthBMJvrxe7+MzM7h2C+/blNtjkPGB22b8Bj4eR/64Ajganu/pqZ3Qt8MyzhTAcmufsKM/sT8A0zuwN4CLjc3eeYWU9gf9jMCQSzf1YBy83sNuAQYIi7jw3j6J3AfpUCpZ6/5BwPZq78E/CvCWw2x4MJvKoILnGPJO9FBAk/4mF3r3f3lQRfEkcB5wFfDKcCfpNgWofR4etnN038oZOAF919qwfT7t5PcKOa1pwX/nsLmB+2HWlnvbu/Fi7/heDo4UhgjbuvCNffF7ZxJLDJ3edAsL/84NTAz7v7Tnc/QHC0clj4c440s9vMbDLQaMZSKU7q+UuuupUgQf4xal0tYYfFzEoIJrGKqIparo96XE/jz3nT+UycoBf+L+7+dPQTZvYRYG9y4cdkwC/d/c4m7ZS3EFcyovdDHVDm7jvM7HiCm5R8HbiMYO4aKWLq+UtOcvftBLe5mxq1ei1BmQXgEwR3akrUpWZWEp4HGEkwQdbTBOWUDgBmdoSZdWvjfWYDZ5lZfzMrBa4EXmpjm6eBr4Tz82NmQ8zskPC54WZ2arj8WeDVMLbysDQF8IWwjeXAYDM7KXyfHq2dkA5Pnpe4+yPAjwlKWVLk1POXXHYL8K2ox38AHjWzt4GnSK5Xvo4gcfcEvu7uB8zsboLS0HwzM2Arbdyez903WXCj7JkEPfrH3f3RNrZ5xsyOBl4PmmEP8HmCHvpyghsA3UtQrvmfMLYvA38Nk/scgql+q83scuA2M+tCUO8/t5WmhwB/DI+WILi5iRQ5zeopkmVh2eefkROyIpmgso+ISBFSz19EpAip5y8iUoSU/EVEipCSv4hIEVLyFxEpQkr+IiJF6P8DA5vNwtAR0NkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "44.35\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}